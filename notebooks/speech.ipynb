{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "https://github.com/kamilc/speech-recognition\n",
    "\n",
    "https://github.com/tensorflow/models/issues/5023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.5)\n",
    "sess_config = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)\n",
    "run_config = tf.estimator.RunConfig(session_config = sess_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE=16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_path(filename):\n",
    "    return './data/' + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_stretch(audio, params):\n",
    "    \"\"\"\n",
    "    Stretches randomly the input audio\n",
    "    \"\"\"\n",
    "    \n",
    "    rate = random.uniform(params['random_stretch_min'], params['random_stretch_max'])\n",
    "    \n",
    "    return librosa.effects.time_stretch(audio, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_shift(audio, params):\n",
    "    \"\"\"\n",
    "    Shifts randomly the input audio to the left or the right\n",
    "    \"\"\"\n",
    "    \n",
    "    _shift = random.randrange(params['random_shift_min'], params['random_shift_max'])\n",
    "    \n",
    "    if _shift < 0:\n",
    "        pad = (_shift * -1, 0)\n",
    "    else:\n",
    "        pad = (0, _shift)\n",
    "    \n",
    "    return np.pad(audio, pad, mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "noise_files = glob.glob('./data/_background_noise_/*.wav')\n",
    "noises = {}\n",
    "\n",
    "def random_noise(audio, params):\n",
    "    _factor = random.uniform(\n",
    "        params['random_noise_factor_min'],\n",
    "        params['random_noise_factor_max']\n",
    "    )    \n",
    "    \n",
    "    if params['random_noise'] > random.uniform(0, 1):\n",
    "        _path = random.choice(noise_files)\n",
    "        \n",
    "        if _path in noises:\n",
    "            wave = noises[_path]\n",
    "        else:\n",
    "            if os.path.isfile(_path + '.wave.hkl'):\n",
    "                wave = hkl.load(_path + '.wave.hkl').astype(np.float32)\n",
    "                noises[_path] = wave\n",
    "            else:\n",
    "                wave, _ = librosa.load(_path, sr=SAMPLING_RATE)\n",
    "                hkl.dump(wave, _path + '.wave.hkl')\n",
    "                noises[_path] = wave\n",
    "\n",
    "        noise = random_shift(\n",
    "            wave,\n",
    "            {\n",
    "                'random_shift_min': -16000,\n",
    "                'random_shift_max': 16000\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        max_noise = np.max(noise[0:len(audio)])\n",
    "        max_wave = np.max(audio)\n",
    "        \n",
    "        noise = noise * (max_wave / max_noise)\n",
    "        \n",
    "        return _factor * noise[0:len(audio)] + (1.0 - _factor) * audio\n",
    "    else:\n",
    "        return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import hickle as hkl\n",
    "import os.path\n",
    "\n",
    "def load_wave(example, absolute=False):\n",
    "    row, params = example\n",
    "    \n",
    "    _path = row.path if absolute else to_path(row.path)\n",
    "    \n",
    "    if os.path.isfile(_path + '.wave.hkl'):\n",
    "        wave = hkl.load(_path + '.wave.hkl').astype(np.float32)\n",
    "    else:\n",
    "        wave, _ = librosa.load(_path, sr=SAMPLING_RATE)\n",
    "        hkl.dump(wave, _path + '.wave.hkl')\n",
    "\n",
    "    if len(wave) <= params['max_wave_length']:\n",
    "        if params['augment'] and row.path.split('/')[0] != 'voxforge':\n",
    "            wave = random_noise(\n",
    "                random_stretch(\n",
    "                    random_shift(\n",
    "                        wave,\n",
    "                        params\n",
    "                    ),\n",
    "                    params\n",
    "                ),\n",
    "                params\n",
    "            )\n",
    "    else:\n",
    "        wave = None\n",
    "    \n",
    "    return wave, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from pypinyin import Style\n",
    "from pypinyin import pinyin_dict\n",
    "from pypinyin.style import convert as convert_style\n",
    "\n",
    "blank = ' '\n",
    "\n",
    "def gen_pinyin_table():\n",
    "    \"\"\" 生成拼音表,长度1543\n",
    "    \"\"\"\n",
    "    pinyin_style_tone3 = set()\n",
    "    # 单字拼音库\n",
    "    PINYIN_DICT = pinyin_dict.pinyin_dict\n",
    "    for k, v in PINYIN_DICT.items():\n",
    "        for single_pinyin in v.split(','):\n",
    "            r = convert_style(single_pinyin, Style.TONE3, strict=True)\n",
    "            pinyin_style_tone3.add(r)\n",
    "    # 声调使用数字表示的相关拼音风格下的结果使用 5 标识轻声\n",
    "    pinyin_style_tone3_list = []\n",
    "    for v in pinyin_style_tone3:\n",
    "        if not re.search(r'\\d$', v):\n",
    "            v = v + '5'\n",
    "        pinyin_style_tone3_list.append(v)\n",
    "    pinyin_style_tone3_list = sorted(pinyin_style_tone3_list)\n",
    "    # remove 'ê1', 'ê2', 'ê3', 'ê4'\n",
    "    pinyin_style_tone3_list = pinyin_style_tone3_list[:-4]\n",
    "    # print(pinyin_style_tone3_list)\n",
    "    # len 1543\n",
    "    # print(len(pinyin_style_tone3_list))\n",
    "    # 添加所有音的轻声\n",
    "    pinyin_style_tone3_set = set(pinyin_style_tone3_list)\n",
    "    for v in pinyin_style_tone3_list:\n",
    "        pinyin_style_tone3_set.add(v[:-1] + '5')\n",
    "    # len 1835\n",
    "    pinyin_style_tone3_list = sorted(list(pinyin_style_tone3_set))\n",
    "    # 保存\n",
    "    with open('./pinyin_table.txt', 'w') as f:\n",
    "        f.write('\\n'.join(pinyin_style_tone3_list))\n",
    "    return pinyin_style_tone3_list\n",
    "\n",
    "pinyin_table = gen_pinyin_table()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypinyin import Style, lazy_pinyin\n",
    "\n",
    "# 汉字\n",
    "RE_HANS = re.compile(\n",
    "    r'^(?:['\n",
    "    r'\\u3007'                  # 〇\n",
    "    r'\\u3400-\\u4dbf'           # CJK扩展A:[3400-4DBF]\n",
    "    r'\\u4e00-\\u9fff'           # CJK基本:[4E00-9FFF]\n",
    "    r'\\uf900-\\ufaff'           # CJK兼容:[F900-FAFF]\n",
    "    r'\\U00020000-\\U0002A6DF'   # CJK扩展B:[20000-2A6DF]\n",
    "    r'\\U0002A703-\\U0002B73F'   # CJK扩展C:[2A700-2B73F]\n",
    "    r'\\U0002B740-\\U0002B81D'   # CJK扩展D:[2B740-2B81D]\n",
    "    r'\\U0002F80A-\\U0002FA1F'   # CJK兼容扩展:[2F800-2FA1F]\n",
    "    r'])+$'\n",
    ")\n",
    "    \n",
    "def preprocess_text(sentence, blank=' '):\n",
    "    \"\"\"\n",
    "    预处理文本,使用` `代替所有标点符号,中文转拼音.\n",
    "    \"\"\"\n",
    "    sentence_r = [] \n",
    "    for c in sentence:\n",
    "        if RE_HANS.match(c):\n",
    "            sentence_r.append(c)\n",
    "        else:\n",
    "            sentence_r.append(blank)\n",
    "    # TODO, use '_'\n",
    "    return ''.join(sentence_r)\n",
    "\n",
    "\n",
    "def han_to_pinyin(sentence):\n",
    "    # TODO deal with ' ' and '_'\n",
    "    pinyin_style_tone3 = lazy_pinyin(sentence, style=Style.TONE3)\n",
    "    pinyin_style_tone3 = [i for i in pinyin_style_tone3  if i.strip()]\n",
    "    # 声调使用数字表示的相关拼音风格下的结果使用 5 标识轻声\n",
    "    pinyin_style_tone3_list = []\n",
    "    for v in pinyin_style_tone3:\n",
    "        if not re.search(r'\\d$', v):\n",
    "            v = v + '5'\n",
    "        pinyin_style_tone3_list.append(v)\n",
    "    return ' '.join(pinyin_style_tone3_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_data = pd.read_csv('./data/cv_corpus_v1/train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤非中文,所以目前的模型不支持英文识别, 也无法区别停顿\n",
    "train_eval_data['sentence_cn'] = train_eval_data['sentence']\n",
    "train_eval_data['sentence'] = train_eval_data['sentence'].apply(preprocess_text)\n",
    "train_eval_data['sentence'] = train_eval_data['sentence'].apply(han_to_pinyin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_eval_data = train_eval_data[train_eval_data.length <= 80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('train.csv'):\n",
    "    eval_data = train_eval_data.sample(n=int(len(train_eval_data) * 0.1 ))\n",
    "    train_data = train_eval_data[~train_eval_data.isin(eval_data)]\n",
    "    eval_data = eval_data[eval_data.path.notnull()]\n",
    "    train_data = train_data[train_data.path.notnull()]\n",
    "    \n",
    "    train_data.to_csv('train.csv', sep='\\t')\n",
    "    eval_data.to_csv('eval.csv', sep='\\t')\n",
    "else:\n",
    "    train_data = pd.read_csv('train.csv', sep='\\t')\n",
    "    eval_data = pd.read_csv('eval.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./data/cv_corpus_v1/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤非中文,所以目前的模型不支持英文识别, 也无法区别停顿\n",
    "test_data['sentence'] = test_data['sentence'].apply(preprocess_text)\n",
    "test_data['sentence'] = test_data['sentence'].apply(han_to_pinyin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['path'] = train_data['path'].apply(lambda f: 'cv_corpus_v1/clips/{}'.format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data['path'] = eval_data['path'].apply(lambda f: 'cv_corpus_v1/clips/{}'.format(f))\n",
    "test_data['path'] = test_data['path'].apply(lambda f: 'cv_corpus_v1/clips/{}'.format(f))\n",
    "eval_data = eval_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('full_train.csv'):\n",
    "    train_data = train_data[['path', 'sentence']]\n",
    "    train_data.to_csv('full_train.csv')\n",
    "else:\n",
    "    train_data = pd.read_csv('full_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lengths(original_lengths, params):\n",
    "    \"\"\"\n",
    "    Computes the length of data for CTC\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.cast(\n",
    "        tf.floor(\n",
    "            (tf.cast(original_lengths, dtype=tf.float32) - params['n_fft']) /\n",
    "                params['frame_step']\n",
    "        ) + 1,\n",
    "        tf.int32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels, params):\n",
    "    characters = list(params['alphabet'])\n",
    "    \n",
    "    table = tf.contrib.lookup.HashTable(\n",
    "        tf.contrib.lookup.KeyValueTensorInitializer(\n",
    "            characters,\n",
    "            list(range(len(characters)))\n",
    "        ),\n",
    "        -1,\n",
    "        name='char2id'\n",
    "    )\n",
    "    \n",
    "    return table.lookup(\n",
    "        tf.string_split(labels, delimiter=' ')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_codes(codes, params):\n",
    "    characters = list(params['alphabet'])\n",
    "    \n",
    "    table = tf.contrib.lookup.HashTable(\n",
    "        tf.contrib.lookup.KeyValueTensorInitializer(\n",
    "            list(range(len(characters))),\n",
    "            characters\n",
    "        ),\n",
    "        '',\n",
    "        name='id2char'\n",
    "    )\n",
    "    \n",
    "    return table.lookup(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/lite/python/__init__.py:26: PendingDeprecationWarning: WARNING: TF Lite has moved from tf.contrib.lite to tf.lite. Please update your imports. This will be a breaking error in TensorFlow version 2.0.\n",
      "  _warnings.warn(WARNING, PendingDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.457s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f0413c7c278>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import random\n",
    "\n",
    "from hypothesis import given, settings, note, assume, reproduce_failure, given\n",
    "from hypothesis import strategies as st\n",
    "\n",
    "def generate_sentence(length=5):\n",
    "    return ' '.join(random.choices(pinyin_table, k=length))\n",
    "\n",
    "\n",
    "class CoderText(unittest.TestCase):\n",
    "    @given(st.builds(generate_sentence))\n",
    "    @settings(deadline=None)\n",
    "    def test_encode_and_decode_work(self, text):\n",
    "\n",
    "        params = { 'alphabet': pinyin_table }\n",
    "        label_ph = tf.placeholder(tf.string, shape=(1), name='text')\n",
    "        codes_op = encode_labels([text], params)\n",
    "        decode_op = decode_codes(codes_op, params)\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            session.run(tf.tables_initializer(name='init_all_tables'))\n",
    "\n",
    "            codes,decoded = session.run(\n",
    "                [codes_op,decode_op],\n",
    "                {\n",
    "                    label_ph: [text]\n",
    "                }\n",
    "            )\n",
    "            self.assertEqual(text, ' '.join(map(lambda s: s.decode('UTF-8'), decoded.values)))\n",
    "            self.assertEqual(codes.values.dtype, np.int32)\n",
    "            self.assertEqual(len(codes.values), len(text.split()))\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_logits(logits, lengths, params):\n",
    "    if len(tf.shape(lengths).shape) == 1:\n",
    "        lengths = tf.reshape(lengths, [1])\n",
    "    else:\n",
    "        lengths = tf.squeeze(lengths)\n",
    "        \n",
    "    predicted_codes, _ = tf.nn.ctc_beam_search_decoder(\n",
    "        tf.transpose(logits, (1, 0, 2)),\n",
    "        lengths,\n",
    "        merge_repeated=True\n",
    "    )\n",
    "    \n",
    "    codes = tf.cast(predicted_codes[0], tf.int32)\n",
    "    \n",
    "    print('codes: {}'.format(codes))\n",
    "    text = decode_codes(codes, params)\n",
    "    \n",
    "    return text, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogMelSpectrogram(tf.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 sampling_rate,\n",
    "                 n_fft,\n",
    "                 frame_step,\n",
    "                 lower_edge_hertz,\n",
    "                 upper_edge_hertz,\n",
    "                 num_mel_bins,\n",
    "                 **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        \n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.frame_step = frame_step\n",
    "        self.lower_edge_hertz = lower_edge_hertz\n",
    "        self.upper_edge_hertz = upper_edge_hertz\n",
    "        self.num_mel_bins = num_mel_bins\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        stfts = tf.contrib.signal.stft(\n",
    "            inputs,\n",
    "            frame_length=self.n_fft,\n",
    "            frame_step=self.frame_step,\n",
    "            fft_length=self.n_fft,\n",
    "            pad_end=False\n",
    "        )\n",
    "        \n",
    "        power_spectrograms = tf.math.real(stfts * tf.math.conj(stfts))\n",
    "        \n",
    "        num_spectrogram_bins = power_spectrograms.shape[-1].value\n",
    "    \n",
    "        linear_to_mel_weight_matrix = tf.constant(\n",
    "            np.transpose(\n",
    "                librosa.filters.mel(\n",
    "                    sr=self.sampling_rate,\n",
    "                    n_fft=self.n_fft + 1,\n",
    "                    n_mels=self.num_mel_bins,\n",
    "                    fmin=self.lower_edge_hertz,\n",
    "                    fmax=self.upper_edge_hertz\n",
    "                )\n",
    "            ),\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        mel_spectrograms = tf.tensordot(\n",
    "            power_spectrograms,\n",
    "            linear_to_mel_weight_matrix,\n",
    "            1\n",
    "        )\n",
    "        \n",
    "        mel_spectrograms.set_shape(\n",
    "            power_spectrograms.shape[:-1].concatenate(\n",
    "                linear_to_mel_weight_matrix.shape[-1:]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return tf.math.log(mel_spectrograms + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtrousConv1D(tf.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 dilation_rate,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer=tf.glorot_normal_initializer(),\n",
    "                 causal=True\n",
    "                ):\n",
    "        super(AtrousConv1D, self).__init__()\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.causal = causal\n",
    "        \n",
    "        self.conv1d = tf.layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            padding='valid' if causal else 'same',\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.causal:\n",
    "            padding = (self.kernel_size - 1) * self.dilation_rate\n",
    "            inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)\n",
    "        \n",
    "        return self.conv1d(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dilation_rate, causal, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        \n",
    "        self.dilated_conv1 = AtrousConv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            causal=causal\n",
    "        )\n",
    "        \n",
    "        self.dilated_conv2 = AtrousConv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            causal=causal\n",
    "        )\n",
    "        \n",
    "        self.out = tf.layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=1\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        data = tf.layers.batch_normalization(\n",
    "            inputs,\n",
    "            training=training\n",
    "        )\n",
    "        \n",
    "        filters = self.dilated_conv1(data)\n",
    "        gates = self.dilated_conv2(data)\n",
    "        \n",
    "        filters = tf.nn.tanh(filters)\n",
    "        gates = tf.nn.sigmoid(gates)\n",
    "        \n",
    "        out = tf.nn.tanh(\n",
    "            self.out(\n",
    "                filters * gates\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return out + inputs, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualStack(tf.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dilation_rates, causal, **kwargs):\n",
    "        super(ResidualStack, self).__init__(**kwargs)\n",
    "        \n",
    "        self.blocks = [\n",
    "            ResidualBlock(\n",
    "                filters=filters,\n",
    "                kernel_size=kernel_size,\n",
    "                dilation_rate=dilation_rate,\n",
    "                causal=causal\n",
    "            )\n",
    "            for dilation_rate in dilation_rates\n",
    "        ]\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        data = inputs\n",
    "        skip = 0\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            data, current_skip = block(data, training=training)\n",
    "            skip += current_skip\n",
    "\n",
    "        return skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechNet(tf.layers.Layer):\n",
    "    def __init__(self, params, **kwargs):\n",
    "        super(SpeechNet, self).__init__(**kwargs)\n",
    "        \n",
    "        self.to_log_mel = LogMelSpectrogram(\n",
    "            sampling_rate=params['sampling_rate'],\n",
    "            n_fft=params['n_fft'],\n",
    "            frame_step=params['frame_step'],\n",
    "            lower_edge_hertz=params['lower_edge_hertz'],\n",
    "            upper_edge_hertz=params['upper_edge_hertz'],\n",
    "            num_mel_bins=params['num_mel_bins']\n",
    "        )\n",
    "        \n",
    "        self.expand = tf.layers.Conv1D(\n",
    "            filters=params['stack_filters'],\n",
    "            kernel_size=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        \n",
    "        self.stacks = [\n",
    "            ResidualStack(\n",
    "                filters=params['stack_filters'],\n",
    "                kernel_size=params['stack_kernel_size'],\n",
    "                dilation_rates=params['stack_dilation_rates'],\n",
    "                causal=params['causal_convolutions']\n",
    "            )\n",
    "            for _ in range(params['stacks'])\n",
    "        ]\n",
    "        \n",
    "        self.out = tf.layers.Conv1D(\n",
    "            filters=len(params['alphabet']) + 1,\n",
    "            kernel_size=1,\n",
    "            padding='same'\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        data = self.to_log_mel(inputs)\n",
    "        \n",
    "        data = tf.layers.batch_normalization(\n",
    "            data,\n",
    "            training=training\n",
    "        )\n",
    "        \n",
    "        if len(data.shape) == 2:\n",
    "            data = tf.expand_dims(data, 0)\n",
    "        \n",
    "        data = self.expand(data)\n",
    "        \n",
    "        for stack in self.stacks:\n",
    "            data = stack(data, training=training)\n",
    "        \n",
    "        data = tf.layers.batch_normalization(\n",
    "            data,\n",
    "            training=training\n",
    "        )\n",
    "        \n",
    "        return self.out(data) + 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# 避免多次调用，内存溢出\n",
    "pool = Pool()\n",
    "\n",
    "def input_fn(input_dataset, params, load_wave_fn=load_wave):\n",
    "    def _input_fn():\n",
    "        \"\"\"\n",
    "        Returns raw audio wave along with the label\n",
    "        \"\"\"\n",
    "        \n",
    "        dataset = input_dataset\n",
    "        \n",
    "        print(params)\n",
    "        \n",
    "        if 'max_text_length' in params and params['max_text_length'] is not None:\n",
    "            print('Constraining dataset to the max_text_length')\n",
    "            dataset = input_dataset[input_dataset.text.str.len() < params['max_text_length']]\n",
    "            \n",
    "        if 'min_text_length' in params and params['min_text_length'] is not None:\n",
    "            print('Constraining dataset to the min_text_length')\n",
    "            dataset = input_dataset[input_dataset.text.str.len() >= params['min_text_length']]\n",
    "            \n",
    "        if 'max_wave_length' in params and params['max_wave_length'] is not None:\n",
    "            print('Constraining dataset to the max_wave_length')\n",
    "            \n",
    "        print('Resulting dataset length: {}'.format(len(dataset)))\n",
    "        \n",
    "        def generator_fn():\n",
    "            buffer = []\n",
    "            \n",
    "            for epoch in range(params['epochs']):\n",
    "                \n",
    "                if params['shuffle']:\n",
    "                    _dataset = dataset.sample(frac=1)\n",
    "                else:\n",
    "                    _dataset = input_dataset\n",
    "                    \n",
    "                for _, row in _dataset.iterrows():\n",
    "                    buffer.append((row, params))\n",
    "\n",
    "                    if len(buffer) >= params['batch_size']:\n",
    "\n",
    "                        if params['parallelize']:\n",
    "                            audios = pool.map(\n",
    "                                load_wave_fn,\n",
    "                                buffer\n",
    "                            )\n",
    "                        else:\n",
    "                            audios = map(\n",
    "                                load_wave_fn,\n",
    "                                buffer\n",
    "                            )\n",
    "\n",
    "                        for audio, row in audios:\n",
    "                            if audio is not None:\n",
    "                                if np.isnan(audio).any():\n",
    "                                    print('SKIPPING! NaN coming from the pipeline!')\n",
    "                                else:\n",
    "                                    #print(row.text)\n",
    "                                    yield (audio, len(audio)), row.sentence.encode()\n",
    "\n",
    "                        buffer = []\n",
    "\n",
    "        return tf.data.Dataset.from_generator(\n",
    "                generator_fn,\n",
    "                output_types=((tf.float32, tf.int32), (tf.string)),\n",
    "                output_shapes=((None,()), (()))\n",
    "            ) \\\n",
    "            .padded_batch(\n",
    "                batch_size=params['batch_size'],\n",
    "                padded_shapes=(\n",
    "                    (tf.TensorShape([None]), tf.TensorShape(())),\n",
    "                    tf.TensorShape(())\n",
    "                )\n",
    "            )\\\n",
    "            .prefetch(1)\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    if isinstance(features, dict):\n",
    "        audio = features['audio']\n",
    "        original_lengths = features['length']\n",
    "    else:\n",
    "        audio, original_lengths = features\n",
    "\n",
    "    lengths = compute_lengths(original_lengths, params)\n",
    "    \n",
    "    if labels is not None:\n",
    "        codes = encode_labels(labels, params)\n",
    "\n",
    "    network = SpeechNet(params)\n",
    "\n",
    "    is_training = mode==tf.estimator.ModeKeys.TRAIN\n",
    "    \n",
    "    print('Is training? {}'.format(is_training))\n",
    "\n",
    "    logits = network(audio, training=is_training)\n",
    "    text, predicted_codes = decode_logits(logits, lengths, params)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'logits': logits,\n",
    "            'text': tf.sparse_tensor_to_dense(\n",
    "                text,\n",
    "                ''\n",
    "            )\n",
    "        }\n",
    "\n",
    "        export_outputs = {\n",
    "            'predictions': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs\n",
    "        )\n",
    "    else:        \n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.ctc_loss(\n",
    "                labels=codes,\n",
    "                inputs=logits,\n",
    "                sequence_length=lengths,\n",
    "                time_major=False,\n",
    "                ignore_longer_outputs_than_inputs=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        mean_edit_distance = tf.reduce_mean(\n",
    "            tf.edit_distance(\n",
    "                tf.cast(predicted_codes, tf.int32),\n",
    "                codes\n",
    "            )\n",
    "        )\n",
    "\n",
    "        distance_metric = tf.metrics.mean(mean_edit_distance)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:            \n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode,\n",
    "                loss=loss,\n",
    "                eval_metric_ops={ 'edit_distance': distance_metric }\n",
    "            )\n",
    "\n",
    "        elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "            tf.summary.text(\n",
    "                'train_predicted_text',\n",
    "                tf.sparse_tensor_to_dense(text, '')\n",
    "            )\n",
    "            tf.summary.scalar('train_edit_distance', mean_edit_distance)\n",
    "\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                train_op = tf.contrib.layers.optimize_loss(\n",
    "                    loss=loss,\n",
    "                    global_step=global_step,\n",
    "                    learning_rate=params['lr'],\n",
    "                    optimizer=(params['optimizer']),\n",
    "                    update_ops=update_ops,\n",
    "                    clip_gradients=params['clip_gradients'],\n",
    "                    summaries=[\n",
    "                        \"learning_rate\",\n",
    "                        \"loss\",\n",
    "                        \"global_gradient_norm\",\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode,\n",
    "                loss=loss,\n",
    "                train_op=train_op\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_name(params, excluded_keys=['alphabet', 'data', 'lr', 'clip_gradients']):\n",
    "\n",
    "    def represent(key, value):\n",
    "        if key in excluded_keys:\n",
    "            return None\n",
    "        else:\n",
    "            if isinstance(value, list):\n",
    "                return '{}_{}'.format(key, '_'.join([str(v) for v in value]))\n",
    "            else:\n",
    "                return '{}_{}'.format(key, value)\n",
    "\n",
    "    parts = filter(\n",
    "        lambda p: p is not None,\n",
    "        [\n",
    "            represent(k, params[k])\n",
    "            for k in sorted(params.keys())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return '/'.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_params(batch_size=32,\n",
    "                   epochs=50000,\n",
    "                   parallelize=True,\n",
    "                   max_text_length=None,\n",
    "                   min_text_length=None,\n",
    "                   max_wave_length=80000,\n",
    "                   shuffle=True,\n",
    "                   random_shift_min=-4000,\n",
    "                   random_shift_max= 4000,\n",
    "                   random_stretch_min=0.7,\n",
    "                   random_stretch_max= 1.3,\n",
    "                   random_noise=0.75,\n",
    "                   random_noise_factor_min=0.2,\n",
    "                   random_noise_factor_max=0.5,\n",
    "                   augment=False):\n",
    "    return {\n",
    "        'parallelize': parallelize,\n",
    "        'shuffle': shuffle,\n",
    "        'max_text_length': max_text_length,\n",
    "        'min_text_length': min_text_length,\n",
    "        'max_wave_length': max_wave_length,\n",
    "        'random_shift_min': random_shift_min,\n",
    "        'random_shift_max': random_shift_max,\n",
    "        'random_stretch_min': random_stretch_min,\n",
    "        'random_stretch_max': random_stretch_max,\n",
    "        'random_noise': random_noise,\n",
    "        'random_noise_factor_min': random_noise_factor_min,\n",
    "        'random_noise_factor_max': random_noise_factor_max,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'augment': augment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_params(data,\n",
    "                      optimizer='Adam',\n",
    "                      lr=1e-4,\n",
    "                      alphabet=\" 'abcdefghijklmnopqrstuvwxyz\",\n",
    "                      causal_convolutions=True,\n",
    "                      stack_dilation_rates= [1, 3, 9, 27, 81],\n",
    "                      stacks=2,\n",
    "                      stack_kernel_size= 3,\n",
    "                      stack_filters= 32,\n",
    "                      sampling_rate=16000,\n",
    "                      n_fft=160*4,\n",
    "                      frame_step=160,\n",
    "                      lower_edge_hertz=0,\n",
    "                      upper_edge_hertz=8000,\n",
    "                      num_mel_bins=160,\n",
    "                      clip_gradients=None,\n",
    "                      codename='regular',\n",
    "                      **kwargs):\n",
    "    params = {\n",
    "        'optimizer': optimizer,\n",
    "        'lr': lr,\n",
    "        'data': data,\n",
    "        'alphabet': alphabet,\n",
    "        'causal_convolutions': causal_convolutions,\n",
    "        'stack_dilation_rates': stack_dilation_rates,\n",
    "        'stacks': stacks,\n",
    "        'stack_kernel_size': stack_kernel_size,\n",
    "        'stack_filters': stack_filters,\n",
    "        'sampling_rate': sampling_rate,\n",
    "        'n_fft': n_fft,\n",
    "        'frame_step': frame_step,\n",
    "        'lower_edge_hertz': lower_edge_hertz,\n",
    "        'upper_edge_hertz': upper_edge_hertz,\n",
    "        'num_mel_bins': num_mel_bins,\n",
    "        'clip_gradients': clip_gradients,\n",
    "        'codename': codename\n",
    "    }\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    \n",
    "    if kwargs is not None and 'data' in kwargs:\n",
    "        params['data'] = { **params['data'], **kwargs['data'] }\n",
    "        del kwargs['data']\n",
    "        \n",
    "    if kwargs is not None:\n",
    "        params = { **params, **kwargs }\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def experiment(data_params=dataset_params(), **kwargs):\n",
    "    params = experiment_params(\n",
    "        data_params,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "#     print(params)\n",
    "    model_dir='stats/{}'.format(experiment_name(params))\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=model_dir,\n",
    "        params=params,\n",
    "        config=run_config\n",
    "    )\n",
    "    \n",
    "#     import pdb; pdb.set_trace()\n",
    "    \n",
    "    hooks = [tf.train.ProfilerHook(save_steps=30, output_dir=model_dir)]\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=input_fn(\n",
    "            train_data,\n",
    "            params['data']\n",
    "        ),\n",
    "        hooks=hooks\n",
    "    )\n",
    "    \n",
    "    features = {\n",
    "        \"audio\": tf.placeholder(dtype=tf.float32, shape=[None]),\n",
    "        \"length\": tf.placeholder(dtype=tf.int32, shape=[])\n",
    "    }\n",
    "    \n",
    "    serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(\n",
    "        features\n",
    "    )\n",
    "    \n",
    "    best_exporter = tf.estimator.BestExporter(\n",
    "      name=\"best_exporter\",\n",
    "      serving_input_receiver_fn=serving_input_receiver_fn,\n",
    "      exports_to_keep=5\n",
    "    )\n",
    "    \n",
    "    eval_params = copy.deepcopy(params['data'])\n",
    "    eval_params['augment'] = False\n",
    "    eval_params['epochs'] = 1\n",
    "    \n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=input_fn(\n",
    "            eval_data,\n",
    "            eval_params\n",
    "        ),\n",
    "        throttle_secs=60*30,\n",
    "        exporters=best_exporter,\n",
    "        steps = 100,\n",
    "    )\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator,\n",
    "        train_spec,\n",
    "        eval_spec\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_params=dataset_params(), **kwargs):\n",
    "    params = experiment_params(\n",
    "        data_params,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    print(params)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir='stats/{}'.format(experiment_name(params)),\n",
    "        params=params,\n",
    "        config=run_config\n",
    "    )\n",
    "    \n",
    "    eval_params = copy.deepcopy(params['data'])\n",
    "    eval_params['augment'] = False\n",
    "    eval_params['epochs'] = 1\n",
    "    eval_params['shuffle'] = False\n",
    "\n",
    "    estimator.evaluate(\n",
    "        input_fn=input_fn(\n",
    "            test_data,\n",
    "            eval_params\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath, **kwargs):\n",
    "    params = experiment_params(\n",
    "        dataset_params(\n",
    "            augment=False,\n",
    "            shuffle=False,\n",
    "            batch_size=1,\n",
    "            epochs=1,\n",
    "            parallelize=False\n",
    "        ),\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    dataset = pd.DataFrame(columns=['path', 'sentence'])\n",
    "    dataset['path'] = [filepath]\n",
    "    dataset['sentence'] = ['']\n",
    "    \n",
    "    print('dataset: {}'.format(dataset))\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir='stats/{}'.format(experiment_name(params)),\n",
    "        params=params,\n",
    "        config=run_config\n",
    "    )\n",
    "\n",
    "    return list(\n",
    "        estimator.predict(\n",
    "            input_fn=input_fn(\n",
    "                dataset,\n",
    "                params['data']\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:                                                 path sentence\n",
      "0  cv_corpus_v1/clips/common_voice_zh-CN_18531538...         \n",
      "INFO:tensorflow:Using config: {'_model_dir': 'stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.5\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04136f1c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "{'parallelize': False, 'shuffle': False, 'max_text_length': None, 'min_text_length': None, 'max_wave_length': 80000, 'random_shift_min': -4000, 'random_shift_max': 4000, 'random_stretch_min': 0.7, 'random_stretch_max': 1.3, 'random_noise': 0.75, 'random_noise_factor_min': 0.2, 'random_noise_factor_max': 0.5, 'epochs': 1, 'batch_size': 1, 'augment': False}\n",
      "params[parallelize] False\n",
      "Constraining dataset to the max_wave_length\n",
      "Resulting dataset length: 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Is training? False\n",
      "WARNING:tensorflow:From <ipython-input-32-8bb2a1feb940>:41: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt-62933\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = predict(\n",
    "    'cv_corpus_v1/clips/common_voice_zh-CN_18531538.mp3',\n",
    "    codename='deep_max_20_seconds',\n",
    "    alphabet=pinyin_table, \n",
    "    causal_convolutions=False,\n",
    "    stack_dilation_rates=[1, 3, 9, 27],\n",
    "    stacks=6,\n",
    "    stack_kernel_size=7,\n",
    "    stack_filters=3*128,\n",
    "    n_fft=160*8,\n",
    "    frame_step=160*4,\n",
    "    num_mel_bins=160,\n",
    "    optimizer='Momentum',\n",
    "    lr=0.00001,\n",
    "    clip_gradients=20.0\n",
    ")\n",
    "b''.join(results[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.5\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f032077b780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "{'parallelize': True, 'shuffle': True, 'max_text_length': None, 'min_text_length': None, 'max_wave_length': 320000, 'random_shift_min': -4000, 'random_shift_max': 4000, 'random_stretch_min': 0.8, 'random_stretch_max': 1.2, 'random_noise': 0.75, 'random_noise_factor_min': 0.1, 'random_noise_factor_max': 0.15, 'epochs': 10000, 'batch_size': 48, 'augment': True}\n",
      "params[parallelize] True\n",
      "Constraining dataset to the max_wave_length\n",
      "Resulting dataset length: 2071\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Is training? True\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:363: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt-62933\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 62933 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "INFO:tensorflow:loss = 113.290375, step = 62933\n",
      "INFO:tensorflow:Saving checkpoints for 63034 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "{'parallelize': True, 'shuffle': True, 'max_text_length': None, 'min_text_length': None, 'max_wave_length': 320000, 'random_shift_min': -4000, 'random_shift_max': 4000, 'random_stretch_min': 0.8, 'random_stretch_max': 1.2, 'random_noise': 0.75, 'random_noise_factor_min': 0.1, 'random_noise_factor_max': 0.15, 'epochs': 1, 'batch_size': 48, 'augment': False}\n",
      "params[parallelize] True\n",
      "Constraining dataset to the max_wave_length\n",
      "Resulting dataset length: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Is training? False\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-26T07:41:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt-63034\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-26-07:41:09\n",
      "INFO:tensorflow:Saving dict for global step 63034: edit_distance = 0.0, global_step = 63034, loss = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 63034: stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt-63034\n",
      "INFO:tensorflow:Loading best metric from event files.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/summary_iterator.py:68: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:global_step/sec: 0.246587\n",
      "INFO:tensorflow:loss = 118.875725, step = 63033 (405.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.259012\n",
      "INFO:tensorflow:loss = 123.65802, step = 63133 (386.083 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 63234 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (1800 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.243214\n",
      "INFO:tensorflow:loss = 124.353615, step = 63233 (411.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.277574\n",
      "INFO:tensorflow:loss = 106.72677, step = 63333 (360.265 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 63434 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (1800 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.251312\n",
      "INFO:tensorflow:loss = 130.60492, step = 63433 (397.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.26167\n",
      "INFO:tensorflow:loss = 112.25869, step = 63533 (382.161 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 63634 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "{'parallelize': True, 'shuffle': True, 'max_text_length': None, 'min_text_length': None, 'max_wave_length': 320000, 'random_shift_min': -4000, 'random_shift_max': 4000, 'random_stretch_min': 0.8, 'random_stretch_max': 1.2, 'random_noise': 0.75, 'random_noise_factor_min': 0.1, 'random_noise_factor_max': 0.15, 'epochs': 1, 'batch_size': 48, 'augment': False}\n",
      "params[parallelize] True\n",
      "Constraining dataset to the max_wave_length\n",
      "Resulting dataset length: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Is training? False\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-26T08:19:58Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt-63634\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-26-08:20:00\n",
      "INFO:tensorflow:Saving dict for global step 63634: edit_distance = 0.0, global_step = 63634, loss = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 63634: stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt-63634\n",
      "INFO:tensorflow:global_step/sec: 0.254394\n",
      "INFO:tensorflow:loss = 127.22959, step = 63633 (393.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.283131\n",
      "INFO:tensorflow:loss = 108.50478, step = 63733 (353.195 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 63834 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (1800 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.254728\n",
      "INFO:tensorflow:loss = 117.91165, step = 63833 (392.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.259624\n",
      "INFO:tensorflow:loss = 121.80182, step = 63933 (385.172 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 64034 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (1800 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.2615\n",
      "INFO:tensorflow:loss = 116.54783, step = 64033 (382.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.263722\n",
      "INFO:tensorflow:loss = 116.17997, step = 64133 (379.189 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 64234 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "{'parallelize': True, 'shuffle': True, 'max_text_length': None, 'min_text_length': None, 'max_wave_length': 320000, 'random_shift_min': -4000, 'random_shift_max': 4000, 'random_stretch_min': 0.8, 'random_stretch_max': 1.2, 'random_noise': 0.75, 'random_noise_factor_min': 0.1, 'random_noise_factor_max': 0.15, 'epochs': 1, 'batch_size': 48, 'augment': False}\n",
      "params[parallelize] True\n",
      "Constraining dataset to the max_wave_length\n",
      "Resulting dataset length: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Is training? False\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-11-26T08:57:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt-64234\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-11-26-08:57:35\n",
      "INFO:tensorflow:Saving dict for global step 64234: edit_distance = 0.0, global_step = 64234, loss = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 64234: stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt-64234\n",
      "INFO:tensorflow:global_step/sec: 0.276406\n",
      "INFO:tensorflow:loss = 108.33908, step = 64233 (361.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.256748\n",
      "INFO:tensorflow:loss = 125.11799, step = 64333 (389.489 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 64434 into stats/causal_convolutions_False/codename_deep_max_20_seconds/frame_step_640/lower_edge_hertz_0/n_fft_1280/num_mel_bins_160/optimizer_Momentum/sampling_rate_16000/stack_dilation_rates_1_3_9_27/stack_filters_384/stack_kernel_size_7/stacks_6/upper_edge_hertz_8000/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (1800 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.267832\n",
      "INFO:tensorflow:loss = 115.001366, step = 64433 (373.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.274125\n",
      "INFO:tensorflow:loss = 110.9316, step = 64533 (364.799 sec)\n"
     ]
    }
   ],
   "source": [
    "experiment(\n",
    "    dataset_params(\n",
    "        parallelize=True,\n",
    "        batch_size=48,\n",
    "        epochs=10000,\n",
    "        max_wave_length=320000,\n",
    "        augment=True,\n",
    "        random_noise=0.75,\n",
    "        random_noise_factor_min=0.1,\n",
    "        random_noise_factor_max=0.15,\n",
    "        random_stretch_min=0.8,\n",
    "        random_stretch_max=1.2\n",
    "    ),\n",
    "    codename='deep_max_20_seconds',\n",
    "    alphabet = pinyin_table,\n",
    "    causal_convolutions=False,\n",
    "    stack_dilation_rates=[1, 3, 9, 27],\n",
    "    stacks=6,\n",
    "    stack_kernel_size=7,\n",
    "    stack_filters=3*128,\n",
    "    n_fft=160*8,\n",
    "    frame_step=160*4,\n",
    "    num_mel_bins=160,\n",
    "    optimizer='Momentum',\n",
    "    lr=0.00001,\n",
    "    clip_gradients=20.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
